{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VOX304/BasicChatbot/blob/main/Preprocessing/TablePrep/PdfImgTable_Prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGiMfhUZStyW"
      },
      "source": [
        "# Python packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZUN0dqhSizq",
        "outputId": "8a9a2946-5293-470b-db3d-d2914de8fdf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.11/dist-packages (1.25.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: img2table in /usr/local/lib/python3.11/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: polars>=1.2 in /usr/local/lib/python3.11/dist-packages (from polars[pandas]>=1.2->img2table) (1.21.0)\n",
            "Requirement already satisfied: pyarrow>=7 in /usr/local/lib/python3.11/dist-packages (from img2table) (18.1.0)\n",
            "Requirement already satisfied: pypdfium2==4.30.0 in /usr/local/lib/python3.11/dist-packages (from img2table) (4.30.0)\n",
            "Requirement already satisfied: opencv-contrib-python>=4 in /usr/local/lib/python3.11/dist-packages (from img2table) (4.11.0.86)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from img2table) (0.60.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from img2table) (4.13.3)\n",
            "Requirement already satisfied: xlsxwriter>=3.0.6 in /usr/local/lib/python3.11/dist-packages (from img2table) (3.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->img2table) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->img2table) (4.13.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->img2table) (0.43.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q ultralytics pdf2image torch torchvision\n",
        "!pip install PyMuPDF pandas img2table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aoik-6ueT_Hw"
      },
      "outputs": [],
      "source": [
        "!pip install -q paddleocr paddlepaddle paddlepaddle-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "eKArBciTSxtB",
        "outputId": "f51da0e9-6486-4503-9a32-00564e69140d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: opencv-contrib-python 4.11.0.86\n",
            "Uninstalling opencv-contrib-python-4.11.0.86:\n",
            "  Successfully uninstalled opencv-contrib-python-4.11.0.86\n",
            "Found existing installation: opencv-python 4.11.0.86\n",
            "Uninstalling opencv-python-4.11.0.86:\n",
            "  Successfully uninstalled opencv-python-4.11.0.86\n",
            "Found existing installation: opencv-contrib-python-headless 4.11.0.86\n",
            "Uninstalling opencv-contrib-python-headless-4.11.0.86:\n",
            "  Successfully uninstalled opencv-contrib-python-headless-4.11.0.86\n",
            "Collecting opencv-contrib-python\n",
            "  Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-contrib-python) (2.0.2)\n",
            "Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "paddleocr 2.10.0 requires opencv-python, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed opencv-contrib-python-4.11.0.86\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cv2"
                ]
              },
              "id": "d65bdcc693734f789df6e69f80fedd64"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip uninstall -y opencv-contrib-python opencv-python\n",
        "!pip uninstall -y opencv-contrib-python-headless\n",
        "!pip install opencv-contrib-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIFCPES2Wtjt",
        "outputId": "2528d4e1-6721-4e00-8c07-09ce3c922fad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencv-contrib-python-headless\n",
            "  Using cached opencv_contrib_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-contrib-python-headless) (2.0.2)\n",
            "Using cached opencv_contrib_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (56.1 MB)\n",
            "Installing collected packages: opencv-contrib-python-headless\n",
            "Successfully installed opencv-contrib-python-headless-4.11.0.86\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-contrib-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rWUxfRTS11i",
        "outputId": "e5c50ce5-56a0-478d-9906-70d0707051fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ximgproc available: True\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "print(\"ximgproc available:\", hasattr(cv2, \"ximgproc\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTZEcpXFVxfd",
        "outputId": "b7a50121-7ba9-49fe-8a26-837c388ec07b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ niBlackThreshold is available!\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "# Check if niBlackThreshold exists in OpenCV\n",
        "if hasattr(cv2.ximgproc, \"niBlackThreshold\"):\n",
        "    print(\"‚úÖ niBlackThreshold is available!\")\n",
        "else:\n",
        "    print(\"‚ùå niBlackThreshold is NOT available!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwhXnH2zV1cq",
        "outputId": "8b4472dc-5e36-4ec1-c882-fc7a148067de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.11.0\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "print(cv2.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oxu1ZVFnS3zO"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUR7ZaBWTgEM"
      },
      "source": [
        "## Import and dowload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z544LroSVLvf"
      },
      "outputs": [],
      "source": [
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfvuwc5GTAIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2bddb68-6ccf-47a9-8a87-3b8e8d01a8de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/paddle/utils/cpp_extension/extension_utils.py:711: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
            "  warnings.warn(warning_message)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "from paddleocr import PaddleOCR\n",
        "from img2table.document import Image as TableImage\n",
        "from img2table.ocr import PaddleOCR as Img2TableOCR\n",
        "from img2table.tables.objects.extraction import ExtractedTable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XH0HopvTEVr",
        "outputId": "b960c575-7a43-4fea-8f12-1a94d9f2fbfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:[comfyui-unsafe-torch] `torch.load` is forcibly loading full weights.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ YOLOv8 Table Detection Model Loaded Successfully!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import logging\n",
        "\n",
        "# üîß Patch torch.load to bypass weight loading errors\n",
        "orig_torch_load = torch.load\n",
        "\n",
        "def torch_wrapper(*args, **kwargs):\n",
        "    logging.warning(\"[comfyui-unsafe-torch] `torch.load` is forcibly loading full weights.\")\n",
        "    kwargs['weights_only'] = False\n",
        "    return orig_torch_load(*args, **kwargs)\n",
        "\n",
        "torch.load = torch_wrapper\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# ‚úÖ Load YOLOv8 table detection model\n",
        "model = YOLO(\"/content/sample_data/TableDetection.pt\")\n",
        "\n",
        "# Check if model is loaded successfully\n",
        "print(\"‚úÖ YOLOv8 Table Detection Model Loaded Successfully!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ocr = PaddleOCR(use_angle_cls=True, lang=\"vi\")\n",
        "img2table_ocr = Img2TableOCR(lang=\"vi\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhKLV2Ckq9Er",
        "outputId": "cc38b68e-d71a-4781-b466-a24286206cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_det_infer.tar to /root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer/en_PP-OCRv3_det_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3910/3910 [00:14<00:00, 264.82it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/PP-OCRv3/multilingual/latin_PP-OCRv3_rec_infer.tar to /root/.paddleocr/whl/rec/latin/latin_PP-OCRv3_rec_infer/latin_PP-OCRv3_rec_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9930/9930 [00:16<00:00, 602.79it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar to /root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer/ch_ppocr_mobile_v2.0_cls_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2138/2138 [00:15<00:00, 135.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025/04/03 03:24:57] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, use_gcu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/root/.paddleocr/whl/rec/latin/latin_PP-OCRv3_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/usr/local/lib/python3.11/dist-packages/paddleocr/ppocr/utils/dict/latin_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, onnx_providers=False, onnx_sess_options=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='vi', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIJZh2GITcQF"
      },
      "source": [
        "## Table Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYurtTl5TJer"
      },
      "outputs": [],
      "source": [
        "\n",
        "def detect_tables(img):\n",
        "    results = model(img)  # YOLOv8 table detection\n",
        "    table_boxes = []\n",
        "\n",
        "    for r in results:\n",
        "        for box in r.boxes.xyxy:\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            table_boxes.append((x1, y1, x2, y2))\n",
        "\n",
        "    return table_boxes\n",
        "\n",
        "def extract_table(img, table_boxes):\n",
        "    extracted_tables = []\n",
        "\n",
        "    for box in table_boxes:\n",
        "        x1, y1, x2, y2 = box\n",
        "        table_img = img[y1:y2, x1:x2]\n",
        "\n",
        "        # Convert NumPy array to bytes\n",
        "        _, buffer = cv2.imencode(\".png\", table_img)\n",
        "        table = TableImage(io.BytesIO(buffer)).extract_tables(ocr=img2table_ocr, borderless_tables=True)\n",
        "\n",
        "        if isinstance(table, list) and table:\n",
        "            extracted_tables.append(table[0])  # Assuming one table per detection\n",
        "\n",
        "    return extracted_tables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1sFOVOCT3Jn",
        "outputId": "6e873ab5-6027-4053-d940-5d8e9e0c0ae2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x480 (no detections), 509.7ms\n",
            "Speed: 8.0ms preprocess, 509.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 496.6ms\n",
            "Speed: 6.9ms preprocess, 496.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 484.5ms\n",
            "Speed: 5.8ms preprocess, 484.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 505.1ms\n",
            "Speed: 5.2ms preprocess, 505.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 493.1ms\n",
            "Speed: 6.1ms preprocess, 493.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 493.7ms\n",
            "Speed: 4.3ms preprocess, 493.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 500.3ms\n",
            "Speed: 3.9ms preprocess, 500.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 510.0ms\n",
            "Speed: 5.2ms preprocess, 510.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 584.6ms\n",
            "Speed: 5.0ms preprocess, 584.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x448 (no detections), 726.4ms\n",
            "Speed: 8.0ms preprocess, 726.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x448 (no detections), 722.1ms\n",
            "Speed: 7.6ms preprocess, 722.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x480 (no detections), 683.9ms\n",
            "Speed: 6.4ms preprocess, 683.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 485.4ms\n",
            "Speed: 5.3ms preprocess, 485.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 502.4ms\n",
            "Speed: 4.4ms preprocess, 502.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 486.9ms\n",
            "Speed: 5.1ms preprocess, 486.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 491.6ms\n",
            "Speed: 4.9ms preprocess, 491.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 500.1ms\n",
            "Speed: 5.1ms preprocess, 500.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 507.2ms\n",
            "Speed: 6.0ms preprocess, 507.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 493.9ms\n",
            "Speed: 5.2ms preprocess, 493.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 498.6ms\n",
            "Speed: 6.1ms preprocess, 498.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 borderless, 517.0ms\n",
            "Speed: 4.5ms preprocess, 517.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 488.0ms\n",
            "Speed: 5.8ms preprocess, 488.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 490.5ms\n",
            "Speed: 4.9ms preprocess, 490.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 bordered, 494.1ms\n",
            "Speed: 5.1ms preprocess, 494.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 520.4ms\n",
            "Speed: 5.0ms preprocess, 520.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 775.1ms\n",
            "Speed: 5.7ms preprocess, 775.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 bordered, 768.6ms\n",
            "Speed: 6.0ms preprocess, 768.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 bordered, 487.9ms\n",
            "Speed: 5.3ms preprocess, 487.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 3 bordereds, 791.9ms\n",
            "Speed: 6.5ms preprocess, 791.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 1 bordered, 507.4ms\n",
            "Speed: 6.1ms preprocess, 507.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 3 bordereds, 502.3ms\n",
            "Speed: 5.7ms preprocess, 502.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 480x640 1 bordered, 487.1ms\n",
            "Speed: 5.3ms preprocess, 487.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 bordered, 504.6ms\n",
            "Speed: 6.2ms preprocess, 504.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 bordered, 489.1ms\n",
            "Speed: 5.2ms preprocess, 489.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 bordered, 1279.8ms\n",
            "Speed: 6.6ms preprocess, 1279.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 480x640 1 bordered, 492.8ms\n",
            "Speed: 5.3ms preprocess, 492.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "0: 640x480 (no detections), 503.2ms\n",
            "Speed: 4.0ms preprocess, 503.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 483.3ms\n",
            "Speed: 5.9ms preprocess, 483.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 511.3ms\n",
            "Speed: 6.3ms preprocess, 511.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 508.3ms\n",
            "Speed: 5.0ms preprocess, 508.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x448 (no detections), 459.4ms\n",
            "Speed: 4.9ms preprocess, 459.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x448 (no detections), 478.9ms\n",
            "Speed: 5.4ms preprocess, 478.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x480 (no detections), 504.8ms\n",
            "Speed: 5.7ms preprocess, 504.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 776.8ms\n",
            "Speed: 8.0ms preprocess, 776.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 765.3ms\n",
            "Speed: 6.3ms preprocess, 765.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 727.8ms\n",
            "Speed: 7.9ms preprocess, 727.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 492.0ms\n",
            "Speed: 5.9ms preprocess, 492.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x448 (no detections), 464.4ms\n",
            "Speed: 4.7ms preprocess, 464.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x480 (no detections), 496.9ms\n",
            "Speed: 7.4ms preprocess, 496.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 495.1ms\n",
            "Speed: 6.3ms preprocess, 495.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 479.9ms\n",
            "Speed: 5.1ms preprocess, 479.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x448 (no detections), 467.1ms\n",
            "Speed: 5.1ms preprocess, 467.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x480 (no detections), 500.3ms\n",
            "Speed: 5.9ms preprocess, 500.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 486.2ms\n",
            "Speed: 5.0ms preprocess, 486.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 489.7ms\n",
            "Speed: 4.3ms preprocess, 489.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 498.7ms\n",
            "Speed: 5.3ms preprocess, 498.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 485.9ms\n",
            "Speed: 5.1ms preprocess, 485.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 492.6ms\n",
            "Speed: 5.4ms preprocess, 492.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 497.1ms\n",
            "Speed: 4.1ms preprocess, 497.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 486.7ms\n",
            "Speed: 6.2ms preprocess, 486.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x448 (no detections), 718.8ms\n",
            "Speed: 7.3ms preprocess, 718.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x480 (no detections), 774.2ms\n",
            "Speed: 8.3ms preprocess, 774.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 755.7ms\n",
            "Speed: 5.6ms preprocess, 755.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x448 (no detections), 465.2ms\n",
            "Speed: 5.6ms preprocess, 465.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x480 (no detections), 498.1ms\n",
            "Speed: 5.3ms preprocess, 498.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 478.1ms\n",
            "Speed: 5.4ms preprocess, 478.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x448 (no detections), 466.7ms\n",
            "Speed: 4.3ms preprocess, 466.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x480 (no detections), 498.6ms\n",
            "Speed: 6.1ms preprocess, 498.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 484.6ms\n",
            "Speed: 5.0ms preprocess, 484.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 488.8ms\n",
            "Speed: 3.9ms preprocess, 488.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 498.2ms\n",
            "Speed: 4.9ms preprocess, 498.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x448 (no detections), 471.1ms\n",
            "Speed: 5.2ms preprocess, 471.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x448 (no detections), 455.5ms\n",
            "Speed: 5.1ms preprocess, 455.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x448 (no detections), 470.4ms\n",
            "Speed: 4.5ms preprocess, 470.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x448 (no detections), 461.2ms\n",
            "Speed: 5.1ms preprocess, 461.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x448 (no detections), 461.2ms\n",
            "Speed: 4.9ms preprocess, 461.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x448 (no detections), 475.0ms\n",
            "Speed: 3.9ms preprocess, 475.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x480 (no detections), 614.2ms\n",
            "Speed: 5.2ms preprocess, 614.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 791.1ms\n",
            "Speed: 7.4ms preprocess, 791.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x448 (no detections), 724.1ms\n",
            "Speed: 8.6ms preprocess, 724.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x480 (no detections), 665.0ms\n",
            "Speed: 5.5ms preprocess, 665.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x448 (no detections), 457.7ms\n",
            "Speed: 5.1ms preprocess, 457.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 640x480 (no detections), 486.6ms\n",
            "Speed: 6.0ms preprocess, 486.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 497.6ms\n",
            "Speed: 6.3ms preprocess, 497.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 481.6ms\n",
            "Speed: 4.7ms preprocess, 481.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 492.4ms\n",
            "Speed: 5.1ms preprocess, 492.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 494.8ms\n",
            "Speed: 5.3ms preprocess, 494.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 488.4ms\n",
            "Speed: 6.2ms preprocess, 488.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 490.4ms\n",
            "Speed: 6.7ms preprocess, 490.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 487.0ms\n",
            "Speed: 5.1ms preprocess, 487.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 486.6ms\n",
            "Speed: 5.7ms preprocess, 486.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 487.5ms\n",
            "Speed: 5.2ms preprocess, 487.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 495.3ms\n",
            "Speed: 6.1ms preprocess, 495.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 500.6ms\n",
            "Speed: 5.8ms preprocess, 500.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 487.4ms\n",
            "Speed: 5.0ms preprocess, 487.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "0: 640x480 (no detections), 798.0ms\n",
            "Speed: 5.3ms preprocess, 798.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "‚úÖ JSON file saved as extracted_tables.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def pdf_to_json(folder_path, output_json=\"extracted_tables.json\", zoom=3.0):\n",
        "    extracted_data = []\n",
        "\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.lower().endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(folder_path, file_name)\n",
        "            doc = fitz.open(pdf_path)\n",
        "\n",
        "            document_tables = {\n",
        "                \"document_name\": file_name,\n",
        "                \"datatype\": \"table\",\n",
        "                \"extracted_content\": []\n",
        "            }\n",
        "\n",
        "            for i, page in enumerate(doc):\n",
        "                # Convert page to image (No storage, process immediately)\n",
        "                pix = page.get_pixmap(matrix=fitz.Matrix(zoom, zoom))\n",
        "                img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.h, pix.w, pix.n)\n",
        "\n",
        "                # Convert grayscale to BGR if needed\n",
        "                if img.shape[-1] == 1:\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "                # Detect and extract tables\n",
        "                table_boxes = detect_tables(img)\n",
        "                extracted_tables = extract_table(img, table_boxes)\n",
        "\n",
        "                # Append extracted tables\n",
        "                for table in extracted_tables:\n",
        "                    if table.df is not None:\n",
        "                        document_tables[\"extracted_content\"].append(table.df.values.tolist())\n",
        "\n",
        "            extracted_data.append(document_tables)\n",
        "\n",
        "    # Save extracted data as JSON\n",
        "    with open(output_json, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(extracted_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(f\"‚úÖ JSON file saved as {output_json}\")\n",
        "\n",
        "# Example usage\n",
        "folder_path = \"/content/sample_data/TCU\"\n",
        "pdf_to_json(folder_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPltHZ6YxR/8rkghEFJ6R4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}