import chainlit as cl
import os
import itertools
from Retrieval import augment_prompt
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.schema import HumanMessage
import asyncio

# Load API keys tá»« biáº¿n mÃ´i trÆ°á»ng
GOOGLE_API_KEYS = [
    os.getenv("GOOGLE_API_KEY_1"),
    os.getenv("GOOGLE_API_KEY_2"),
]

gemini_models = itertools.cycle([
    ChatGoogleGenerativeAI(google_api_key=GOOGLE_API_KEYS[0], model="gemini-2.0-flash-thinking-exp-01-21", temperature=0.7),
    ChatGoogleGenerativeAI(google_api_key=GOOGLE_API_KEYS[1], model="gemini-2.0-pro-exp-02-05", temperature=0.7),
    ChatGoogleGenerativeAI(google_api_key=GOOGLE_API_KEYS[0], model="gemini-2.0-flash-thinking-exp-01-21", temperature=0.7),
    ChatGoogleGenerativeAI(google_api_key=GOOGLE_API_KEYS[1], model="gemini-2.0-pro-exp-02-05", temperature=0.7),
])

# LÆ°u lá»‹ch sá»­ há»™i thoáº¡i cá»§a ngÆ°á»i dÃ¹ng
user_histories = {}

@cl.on_chat_start
async def main():
    await cl.Message(content="ğŸ“ Xin chÃ o! TÃ´i lÃ  Uni-chatbot cá»§a TrÆ°á»ng SÄ© Quan ThÃ´ng Tin. Báº¡n cáº§n giÃºp gÃ¬?").send()

@cl.on_message
async def handle_message(message: cl.Message):
    user_id = message.author  
    query = message.content.strip().lower()

    # Xá»­ lÃ½ yÃªu cáº§u thoÃ¡t
    if query in ['bye', 'táº¡m biá»‡t', 'exit']:
        res = await cl.AskActionMessage(
            content="ğŸ“Š Báº¡n cÃ³ hÃ i lÃ²ng vá»›i cÃ¢u tráº£ lá»i cá»§a tÃ´i khÃ´ng?",
            actions=[
                cl.Action(name="YES", value="YES", label="ğŸ‘ CÃ³"),
                cl.Action(name="NO", value="NO", label="ğŸ‘ KhÃ´ng")
            ]
        )
        if res:
            await cl.Message(content=f"ğŸ™ Cáº£m Æ¡n pháº£n há»“i cá»§a báº¡n: {res['value']}!").send()
        return

    # LÆ°u lá»‹ch sá»­ tin nháº¯n
    if user_id not in user_histories:
        user_histories[user_id] = []
    user_histories[user_id].append({"role": "user", "content": query})

    # ğŸ”¹ Gá»i `augment_prompt()` vá»›i lá»‹ch sá»­ há»™i thoáº¡i
    augmented_prompt, source_map = augment_prompt(query, user_histories[user_id])

    # Chá»n mÃ´ hÃ¬nh Gemini (luÃ¢n phiÃªn)
    gemini = next(gemini_models)

    # Táº¡o prompt cho Gemini
    prompt = HumanMessage(content=augmented_prompt)

    # Gá»­i tin nháº¯n rá»—ng trÆ°á»›c Ä‘á»ƒ chuáº©n bá»‹ streaming
    msg = cl.Message(content="")
    await msg.send()

    # ğŸ”¹ Streaming pháº£n há»“i tá»« Gemini
    response_text = ""
    async for chunk in gemini.astream([prompt]):
        if chunk.content:
            await msg.stream_token(chunk.content)
            response_text += chunk.content  

    # LÆ°u pháº£n há»“i vÃ o lá»‹ch sá»­ há»™i thoáº¡i
    user_histories[user_id].append({"role": "assistant", "content": response_text})

    # ğŸ”¹ Hiá»ƒn thá»‹ nguá»“n tÃ i liá»‡u sau khi hoÃ n táº¥t cÃ¢u tráº£ lá»i
    sources = [f"{source} (Trang {page+1})" for text, (source, page) in source_map.items()]
    sources_text = "\n".join(sources) if sources else "KhÃ´ng cÃ³ tÃ i liá»‡u phÃ¹ há»£p."
    await cl.Message(content=f"**ğŸ“š Nguá»“n tÃ i liá»‡u:**\n{sources_text}").send()
    
    # Cáº­p nháº­t sidebar vá»›i lá»‹ch sá»­ há»™i thoáº¡i má»›i nháº¥t
    await update_sidebar(user_id)

async def update_sidebar(user_id):
    """
    Cáº­p nháº­t lá»‹ch sá»­ há»™i thoáº¡i trong sidebar.
    """
    sidebar_content = ""
    for message in user_histories[user_id]:
        role = "ğŸ‘¨â€ğŸ“ Sinh viÃªn" if message["role"] == "user" else "ğŸ¤– Uni-chatbot"
        sidebar_content += f"**{role}:** {message['content']}\n\n"

    await cl.Sidebar(content=sidebar_content).send()

# Cháº¡y Chainlit app
if __name__ == "__main__":
    cl.run(port=8000)  # âœ… Sá»­ dá»¥ng `cl.run()` thay vÃ¬ `cl.main()`
